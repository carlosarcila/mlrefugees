{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook creates syntetic populations and estimate the probability of rejection towards refugges for each place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)\n",
    "Version for Colab at: https://drive.google.com/file/d/1S5gBENvdqqWD3f2Tj-vIGsxvhiptRvSX/view?usp=sharing\n",
    "\n",
    "Models at: https://www.dropbox.com/sh/kdomovxdgc4vzpj/AAAMHg-CbqJcYIruw6Kl_dEBa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosarcila/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator StandardScaler from version 0.18.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/carlosarcila/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.18.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/carlosarcila/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.18.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/carlosarcila/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.18.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/carlosarcila/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SVC from version 0.18.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#import sc and models\n",
    "\n",
    "##TOTAL##\n",
    "open_file = open(\"models/sc.pickle\", \"rb\")\n",
    "sc = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models/lr.pickle\", \"rb\")\n",
    "lr = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models/tree.pickle\", \"rb\")\n",
    "tree = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models/forest.pickle\", \"rb\")\n",
    "forest= pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models/svm.pickle\", \"rb\")\n",
    "svm = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models/svm2.pickle\", \"rb\")\n",
    "svm2 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models/knn.pickle\", \"rb\")\n",
    "knn = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "##_models_nov_2015##\n",
    "open_file = open(\"models_nov_2015/sc.pickle\", \"rb\")\n",
    "sc_models_nov_2015 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2015/lr.pickle\", \"rb\")\n",
    "lr_models_nov_2015 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2015/tree.pickle\", \"rb\")\n",
    "tree_models_nov_2015 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2015/forest.pickle\", \"rb\")\n",
    "forest_models_nov_2015 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2015/svm.pickle\", \"rb\")\n",
    "svm_models_nov_2015 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2015/svm2.pickle\", \"rb\")\n",
    "svm2_models_nov_2015 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2015/knn.pickle\", \"rb\")\n",
    "knn_models_nov_2015 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "##_models_may_2016##\n",
    "open_file = open(\"models_may_2016/sc.pickle\", \"rb\")\n",
    "sc_models_may_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2016/lr.pickle\", \"rb\")\n",
    "lr_models_may_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2016/tree.pickle\", \"rb\")\n",
    "tree_models_may_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2016/forest.pickle\", \"rb\")\n",
    "forest_models_may_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2016/svm.pickle\", \"rb\")\n",
    "svm_models_may_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2016/svm2.pickle\", \"rb\")\n",
    "svm2_models_may_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2016/knn.pickle\", \"rb\")\n",
    "knn_models_may_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "##_models_nov_2016##\n",
    "open_file = open(\"models_nov_2016/sc.pickle\", \"rb\")\n",
    "sc_models_nov_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2016/lr.pickle\", \"rb\")\n",
    "lr_models_nov_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2016/tree.pickle\", \"rb\")\n",
    "tree_models_nov_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2016/forest.pickle\", \"rb\")\n",
    "forest_models_nov_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2016/svm.pickle\", \"rb\")\n",
    "svm_models_nov_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2016/svm2.pickle\", \"rb\")\n",
    "svm2_models_nov_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2016/knn.pickle\", \"rb\")\n",
    "knn_models_nov_2016 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "##_models_may_2017##\n",
    "open_file = open(\"models_may_2017/sc.pickle\", \"rb\")\n",
    "sc_models_may_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2017/lr.pickle\", \"rb\")\n",
    "lr_models_may_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2017/tree.pickle\", \"rb\")\n",
    "tree_models_may_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2017/forest.pickle\", \"rb\")\n",
    "forest_models_may_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2017/svm.pickle\", \"rb\")\n",
    "svm_models_may_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2017/svm2.pickle\", \"rb\")\n",
    "svm2_models_may_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_may_2017/knn.pickle\", \"rb\")\n",
    "knn_models_may_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "##_models_nov_2017##\n",
    "open_file = open(\"models_nov_2017/sc.pickle\", \"rb\")\n",
    "sc_models_nov_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2017/lr.pickle\", \"rb\")\n",
    "lr_models_nov_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2017/tree.pickle\", \"rb\")\n",
    "tree_models_nov_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2017/forest.pickle\", \"rb\")\n",
    "forest_models_nov_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2017/svm.pickle\", \"rb\")\n",
    "svm_models_nov_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2017/svm2.pickle\", \"rb\")\n",
    "svm2_models_nov_2017 = pickle.load(open_file)\n",
    "open_file.close()\n",
    "open_file = open(\"models_nov_2017/knn.pickle\", \"rb\")\n",
    "knn_models_nov_2017 = pickle.load(open_file)\n",
    "open_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "0\tnative\n",
    "1\teducational\n",
    "2\tage\n",
    "3\thousehold_composition\n",
    "4\tcountry_BALGARIJA\n",
    "5\tcountry_BELGIQUE\n",
    "6\tcountry_CESKA REPUBLIKA\n",
    "7\tcountry_DANMARK\n",
    "8\tcountry_DEUTSCHLAND OST\n",
    "9\tcountry_DEUTSCHLAND WEST\n",
    "10\tcountry_EESTI\n",
    "11\tcountry_ELLADA\n",
    "12\tcountry_ESPANA\n",
    "13\tcountry_FRANCE\n",
    "14\tcountry_GREAT BRITAIN\n",
    "15\tcountry_HRVATSKA\n",
    "16\tcountry_IRELAND\n",
    "17\tcountry_ITALIA\n",
    "18\tcountry_KYPROS\n",
    "19\tcountry_LATVIA\n",
    "20\tcountry_LIETUVA\n",
    "21\tcountry_LUXEMBOURG\n",
    "22\tcountry_MAGYARORSZAG\n",
    "23\tcountry_MALTA\n",
    "24\tcountry_NEDERLAND\n",
    "25\tcountry_POLSKA\n",
    "26\tcountry_PORTUGAL\n",
    "27\tcountry_ROMANIA\n",
    "28\tcountry_SLOVENIJA\n",
    "29\tcountry_SLOVENSKA REPUBLIC\n",
    "30\tcountry_SUOMI\n",
    "31\tcountry_SVERIGE\n",
    "32\tcountry_ÖSTERREICH\n",
    "33\tmarital_status_Divorced/Separated\n",
    "34\tmarital_status_Married\n",
    "35\tmarital_status_Partnership\n",
    "36\tmarital_status_Single\n",
    "37\tmarital_status_Widow\n",
    "38\tgender_Man\n",
    "39\tgender_Woman\n",
    "40\toccupation_Employed\n",
    "41\toccupation_Not active\n",
    "42\toccupation_Unemployed\n",
    "43\ttype_community_Large town\n",
    "44\ttype_community_Rural area or village\n",
    "45\ttype_community_Small/middle town"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosarcila/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE72', 0.88945668773854014, 0.69006592212323581, 0.84161752835130832, 0.75627481281441145, 0.64367942609190709, 0.97604000000000013, 0.84496675074342187, 0.69805338445656961, 0.69115020555613971, 0.75272252417322416, 0.64830499961193122, 0.90212000000000003, 0.89139435333281491, 0.6687436603390815, 0.86505821758796775, 0.74613779542313852, 0.62157687723310506, 0.99095999999999984, 0.91394743293142677, 0.68754443338546867, 0.90244986460177246, 0.74450315548828272, 0.6354554010224579, 0.98503999999999992, 0.91696584618538579, 0.69831730769230782, 0.84099995032659858, 0.76550110740319854, 0.64810192843943071, 0.91822000000000004, 0.90837208183984763, 0.66953091984786595, 0.9108731047008547, 0.74991698205427837, 0.64836175695033393, 0.99012000000000011]\n"
     ]
    }
   ],
   "source": [
    "Code_of_nuts2 = 'DE72'\n",
    "#Total_Population =  1025111\n",
    "Total_Population =  10000\n",
    "\n",
    "#Native\n",
    "#0= Foreigner, 1= Native\n",
    "native = np.array([.93,.07]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#Educational\n",
    "#0. No formal education\t<10\n",
    "#1. ISCED Level 1. Primary education\t10-12\n",
    "#2. ISCED Level 2. Lower secondary education\t13-15\n",
    "#3. ISCED Level 3. Upper secondary education\t16-18\n",
    "#4. ISCED Level 4. Post secondary non-tertiary education, ISCED Level 5. First stage of tertiary education, ISCED Level 6. Second Stage of tertiary education\t>18\n",
    "educational = np.array([.0,.07,.20,.46,.27]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "# age (RECODIFICAR EN MODELOS)\n",
    "# 0 = under 15 years\n",
    "# 1 = 15 to 29 years\n",
    "# 2 = 30 to 49 years\n",
    "# 3 = 50 to 64 years\n",
    "# 4 = 65 to 84 years\n",
    "# 5 = 85 years and over\n",
    "age = np.array([.14,.19,.28,.20,.17,.02]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#household_composition (RECODIFICAR EN MODELOS)\n",
    "# 0 = 1 person\n",
    "# 1 = 2 persons\n",
    "# 2 = 3 to 5 persons\n",
    "# 3 = 6 and more persons\n",
    "household_composition = np.array([.33,.34,.31,.02]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "####En los datos de JAVI falta separar las ALemanias\n",
    "#COUNTRIES\n",
    "#country_BALGARIJA\n",
    "#0= NO, 1= YES\n",
    "country_BALGARIJA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_BELGIQUE = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_CESKA_REPUBLIKA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_DANMARK = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_DEUTSCHLAND_OST = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_DEUTSCHLAND_WEST = np.array([0,1]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_EESTI = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ELLADA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ESPANA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_FRANCE = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_GREAT_BRITAIN = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_HRVATSKA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_IRELAND = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ITALIA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_KYPROS = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_LATVIA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_LIETUVA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_LUXEMBOURG = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_MAGYARORSZAG = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_MALTA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_NEDERLAND = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_POLSKA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_PORTUGAL = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ROMANIA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SLOVENIJA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SLOVENSKA_REPUBLIC = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SUOMI = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SVERIGE = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ÖSTERREICH = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#type_community\n",
    "#0= NO, 1= YES\n",
    "type_community_Large_town = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "type_community_Rural_area_village = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "type_community_Small_middle_town = np.array([0,1]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#occupation\n",
    "#0= NO, 1= YES\n",
    "occupation_Employed = np.array([.50,.50]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "occupation_Not_active = np.array([.52,.48]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "occupation_Unemployed = np.array([.98,.02]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#GENDER\n",
    "#0= NO, 1= YES\n",
    "gender_Man = np.array([.51,.49]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "gender_Woman = np.array([.49,.51]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#marital_status\n",
    "#0= NO, 1= YES\n",
    "marital_status_Divorced_Separated = np.array([.94,.06]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Married = np.array([.53,.47]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Partnership = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Single = np.array([.60,.40]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Widow = np.array([.93,.07]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#generation of synthetic population\n",
    "features = [native, educational, age, household_composition, country_BALGARIJA, country_BELGIQUE, country_CESKA_REPUBLIKA, country_DANMARK, country_DEUTSCHLAND_OST, country_DEUTSCHLAND_WEST, country_EESTI, country_ELLADA, country_ESPANA, country_FRANCE, country_GREAT_BRITAIN, country_HRVATSKA, country_IRELAND, country_ITALIA, country_KYPROS, country_LATVIA, country_LIETUVA, country_LUXEMBOURG, country_MAGYARORSZAG, country_MALTA, country_NEDERLAND, country_POLSKA, country_PORTUGAL, country_ROMANIA, country_SLOVENIJA, country_SLOVENSKA_REPUBLIC, country_SUOMI, country_SVERIGE, country_ÖSTERREICH, marital_status_Divorced_Separated, marital_status_Married, marital_status_Partnership, marital_status_Single, marital_status_Widow, gender_Man, gender_Woman, occupation_Employed, occupation_Not_active, occupation_Unemployed, type_community_Large_town, type_community_Rural_area_village, type_community_Small_middle_town]\n",
    "df = pd.DataFrame(features)\n",
    "df = df.T\n",
    "population = df.as_matrix()\n",
    "\n",
    "#pickle.dump(population, open( \"models/DE72.pickle\", \"wb\" ) )\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "population_std = sc.transform(population)\n",
    "##TOTAL##\n",
    "prob_lr = lr.predict_proba(population_std)\n",
    "prob_lr = prob_lr[:, 0]\n",
    "prob_lr = np.average(prob_lr)\n",
    "prob_tree = tree.predict_proba(population)\n",
    "prob_tree = prob_tree[:, 0]\n",
    "prob_tree = np.average(prob_tree)\n",
    "prob_forest = forest.predict_proba(population)\n",
    "prob_forest = prob_forest[:, 0]\n",
    "prob_forest = np.average(prob_forest)\n",
    "prob_svm = svm.predict_proba(population_std)\n",
    "prob_svm = prob_svm[:, 0]\n",
    "prob_svm = np.average(prob_svm)\n",
    "prob_svm2 = svm2.predict_proba(population_std)\n",
    "prob_svm2 = prob_svm2[:, 0]\n",
    "prob_svm2 = np.average(prob_svm2)\n",
    "prob_knn = knn.predict_proba(population)\n",
    "prob_knn = prob_knn[:, 0]\n",
    "prob_knn = np.average(prob_knn)\n",
    "\n",
    "population_std = sc_models_nov_2015.transform(population)\n",
    "##models_nov_2015##\n",
    "prob_lr_models_nov_2015 = lr_models_nov_2015.predict_proba(population_std)\n",
    "prob_lr_models_nov_2015 = prob_lr_models_nov_2015[:, 0]\n",
    "prob_lr_models_nov_2015 = np.average(prob_lr_models_nov_2015)\n",
    "prob_tree_models_nov_2015 = tree_models_nov_2015.predict_proba(population)\n",
    "prob_tree_models_nov_2015 = prob_tree_models_nov_2015[:, 0]\n",
    "prob_tree_models_nov_2015 = np.average(prob_tree_models_nov_2015)\n",
    "prob_forest_models_nov_2015 = forest_models_nov_2015.predict_proba(population)\n",
    "prob_forest_models_nov_2015 = prob_forest_models_nov_2015[:, 0]\n",
    "prob_forest_models_nov_2015 = np.average(prob_forest_models_nov_2015)\n",
    "prob_svm_models_nov_2015 = svm_models_nov_2015.predict_proba(population_std)\n",
    "prob_svm_models_nov_2015 = prob_svm_models_nov_2015[:, 0]\n",
    "prob_svm_models_nov_2015 = np.average(prob_svm_models_nov_2015)\n",
    "prob_svm2_models_nov_2015 = svm2_models_nov_2015.predict_proba(population_std)\n",
    "prob_svm2_models_nov_2015 = prob_svm2_models_nov_2015[:, 0]\n",
    "prob_svm2_models_nov_2015 = np.average(prob_svm2_models_nov_2015)\n",
    "prob_knn_models_nov_2015 = knn_models_nov_2015.predict_proba(population)\n",
    "prob_knn_models_nov_2015 = prob_knn_models_nov_2015[:, 0]\n",
    "prob_knn_models_nov_2015 = np.average(prob_knn_models_nov_2015)\n",
    "population_std = sc_models_may_2016.transform(population)\n",
    "##models_may_2016##\n",
    "prob_lr_models_may_2016 = lr_models_may_2016.predict_proba(population_std)\n",
    "prob_lr_models_may_2016 = prob_lr_models_may_2016[:, 0]\n",
    "prob_lr_models_may_2016 = np.average(prob_lr_models_may_2016)\n",
    "prob_tree_models_may_2016 = tree_models_may_2016.predict_proba(population)\n",
    "prob_tree_models_may_2016 = prob_tree_models_may_2016[:, 0]\n",
    "prob_tree_models_may_2016 = np.average(prob_tree_models_may_2016)\n",
    "prob_forest_models_may_2016 = forest_models_may_2016.predict_proba(population)\n",
    "prob_forest_models_may_2016 = prob_forest_models_may_2016[:, 0]\n",
    "prob_forest_models_may_2016 = np.average(prob_forest_models_may_2016)\n",
    "prob_svm_models_may_2016 = svm_models_may_2016.predict_proba(population_std)\n",
    "prob_svm_models_may_2016 = prob_svm_models_may_2016[:, 0]\n",
    "prob_svm_models_may_2016 = np.average(prob_svm_models_may_2016)\n",
    "prob_svm2_models_may_2016 = svm2_models_may_2016.predict_proba(population_std)\n",
    "prob_svm2_models_may_2016 = prob_svm2_models_may_2016[:, 0]\n",
    "prob_svm2_models_may_2016 = np.average(prob_svm2_models_may_2016)\n",
    "prob_knn_models_may_2016 = knn_models_may_2016.predict_proba(population)\n",
    "prob_knn_models_may_2016 = prob_knn_models_may_2016[:, 0]\n",
    "prob_knn_models_may_2016 = np.average(prob_knn_models_may_2016)\n",
    "\n",
    "population_std = sc_models_nov_2016.transform(population)\n",
    "##models_may_2016##\n",
    "prob_lr_models_nov_2016 = lr_models_nov_2016.predict_proba(population_std)\n",
    "prob_lr_models_nov_2016 = prob_lr_models_nov_2016[:, 0]\n",
    "prob_lr_models_nov_2016 = np.average(prob_lr_models_nov_2016)\n",
    "prob_tree_models_nov_2016 = tree_models_nov_2016.predict_proba(population)\n",
    "prob_tree_models_nov_2016 = prob_tree_models_nov_2016[:, 0]\n",
    "prob_tree_models_nov_2016 = np.average(prob_tree_models_nov_2016)\n",
    "prob_forest_models_nov_2016 = forest_models_nov_2016.predict_proba(population)\n",
    "prob_forest_models_nov_2016 = prob_forest_models_nov_2016[:, 0]\n",
    "prob_forest_models_nov_2016 = np.average(prob_forest_models_nov_2016)\n",
    "prob_svm_models_nov_2016 = svm_models_nov_2016.predict_proba(population_std)\n",
    "prob_svm_models_nov_2016 = prob_svm_models_nov_2016[:, 0]\n",
    "prob_svm_models_nov_2016 = np.average(prob_svm_models_nov_2016)\n",
    "prob_svm2_models_nov_2016 = svm2_models_nov_2016.predict_proba(population_std)\n",
    "prob_svm2_models_nov_2016 = prob_svm2_models_nov_2016[:, 0]\n",
    "prob_svm2_models_nov_2016 = np.average(prob_svm2_models_nov_2016)\n",
    "prob_knn_models_nov_2016 = knn_models_nov_2016.predict_proba(population)\n",
    "prob_knn_models_nov_2016 = prob_knn_models_nov_2016[:, 0]\n",
    "prob_knn_models_nov_2016 = np.average(prob_knn_models_nov_2016)\n",
    "population_std = sc_models_may_2017.transform(population)\n",
    "##models_may_2016##\n",
    "prob_lr_models_may_2017 = lr_models_may_2017.predict_proba(population_std)\n",
    "prob_lr_models_may_2017 = prob_lr_models_may_2017[:, 0]\n",
    "prob_lr_models_may_2017 = np.average(prob_lr_models_may_2017)\n",
    "prob_tree_models_may_2017 = tree_models_may_2017.predict_proba(population)\n",
    "prob_tree_models_may_2017 = prob_tree_models_may_2017[:, 0]\n",
    "prob_tree_models_may_2017 = np.average(prob_tree_models_may_2017)\n",
    "prob_forest_models_may_2017 = forest_models_may_2017.predict_proba(population)\n",
    "prob_forest_models_may_2017 = prob_forest_models_may_2017[:, 0]\n",
    "prob_forest_models_may_2017 = np.average(prob_forest_models_may_2017)\n",
    "prob_svm_models_may_2017 = svm_models_may_2017.predict_proba(population_std)\n",
    "prob_svm_models_may_2017 = prob_svm_models_may_2017[:, 0]\n",
    "prob_svm_models_may_2017 = np.average(prob_svm_models_may_2017)\n",
    "prob_svm2_models_may_2017 = svm2_models_may_2017.predict_proba(population_std)\n",
    "prob_svm2_models_may_2017 = prob_svm2_models_may_2017[:, 0]\n",
    "prob_svm2_models_may_2017 = np.average(prob_svm2_models_may_2017)\n",
    "prob_knn_models_may_2017 = knn_models_may_2017.predict_proba(population)\n",
    "prob_knn_models_may_2017 = prob_knn_models_may_2017[:, 0]\n",
    "prob_knn_models_may_2017 = np.average(prob_knn_models_may_2017)\n",
    "population_std = sc_models_nov_2017.transform(population)\n",
    "##models_may_2016##\n",
    "prob_lr_models_nov_2017 = lr_models_nov_2017.predict_proba(population_std)\n",
    "prob_lr_models_nov_2017 = prob_lr_models_nov_2017[:, 0]\n",
    "prob_lr_models_nov_2017 = np.average(prob_lr_models_nov_2017)\n",
    "prob_tree_models_nov_2017 = tree_models_nov_2017.predict_proba(population)\n",
    "prob_tree_models_nov_2017 = prob_tree_models_nov_2017[:, 0]\n",
    "prob_tree_models_nov_2017 = np.average(prob_tree_models_nov_2017)\n",
    "prob_forest_models_nov_2017 = forest_models_nov_2017.predict_proba(population)\n",
    "prob_forest_models_nov_2017 = prob_forest_models_nov_2017[:, 0]\n",
    "prob_forest_models_nov_2017 = np.average(prob_forest_models_nov_2017)\n",
    "prob_svm_models_nov_2017 = svm_models_nov_2017.predict_proba(population_std)\n",
    "prob_svm_models_nov_2017 = prob_svm_models_nov_2017[:, 0]\n",
    "prob_svm_models_nov_2017 = np.average(prob_svm_models_nov_2017)\n",
    "prob_svm2_models_nov_2017 = svm2_models_nov_2017.predict_proba(population_std)\n",
    "prob_svm2_models_nov_2017 = prob_svm2_models_nov_2017[:, 0]\n",
    "prob_svm2_models_nov_2017 = np.average(prob_svm2_models_nov_2017)\n",
    "prob_knn_models_nov_2017 = knn_models_nov_2017.predict_proba(population)\n",
    "prob_knn_models_nov_2017 = prob_knn_models_nov_2017[:, 0]\n",
    "prob_knn_models_nov_2017 = np.average(prob_knn_models_nov_2017)\n",
    "\n",
    "\n",
    "print([Code_of_nuts2, prob_lr, prob_tree, prob_forest, prob_svm, prob_svm2, prob_knn, \n",
    "       prob_lr_models_nov_2015, prob_tree_models_nov_2015, prob_forest_models_nov_2015, prob_svm_models_nov_2015, \n",
    "       prob_svm2_models_nov_2015, prob_knn_models_nov_2015, prob_lr_models_may_2016, prob_tree_models_may_2016, \n",
    "       prob_forest_models_may_2016, prob_svm_models_may_2016, prob_svm2_models_may_2016, prob_knn_models_may_2016, \n",
    "       prob_lr_models_nov_2016, prob_tree_models_nov_2016, prob_forest_models_nov_2016, prob_svm_models_nov_2016, \n",
    "       prob_svm2_models_nov_2016, prob_knn_models_nov_2016, prob_lr_models_may_2017, prob_tree_models_may_2017, \n",
    "       prob_forest_models_may_2017, prob_svm_models_may_2017, prob_svm2_models_may_2017, prob_knn_models_may_2017, \n",
    "       prob_lr_models_nov_2017, prob_tree_models_nov_2017, prob_forest_models_nov_2017, prob_svm_models_nov_2017, \n",
    "       prob_svm2_models_nov_2017, prob_knn_models_nov_2017])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Code_of_nuts2 = 'DE72'\n",
    "#Total_Population =  1025111\n",
    "Total_Population =  10000\n",
    "\n",
    "#Native\n",
    "#0= Foreigner, 1= Native\n",
    "native = np.array([.93,.07]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#Educational\n",
    "#0. No formal education\t<10\n",
    "#1. ISCED Level 1. Primary education\t10-12\n",
    "#2. ISCED Level 2. Lower secondary education\t13-15\n",
    "#3. ISCED Level 3. Upper secondary education\t16-18\n",
    "#4. ISCED Level 4. Post secondary non-tertiary education, ISCED Level 5. First stage of tertiary education, ISCED Level 6. Second Stage of tertiary education\t>18\n",
    "educational = np.array([.0,.07,.20,.46,.27]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "# age (RECODIFICAR EN MODELOS)\n",
    "# 0 = under 15 years\n",
    "# 1 = 15 to 29 years\n",
    "# 2 = 30 to 49 years\n",
    "# 3 = 50 to 64 years\n",
    "# 4 = 65 to 84 years\n",
    "# 5 = 85 years and over\n",
    "age = np.array([.14,.19,.28,.20,.17,.02]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#household_composition (RECODIFICAR EN MODELOS)\n",
    "# 0 = 1 person\n",
    "# 1 = 2 persons\n",
    "# 2 = 3 to 5 persons\n",
    "# 3 = 6 and more persons\n",
    "household_composition = np.array([.33,.34,.31,.02]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "####En los datos de JAVI falta separar las ALemanias\n",
    "#COUNTRIES\n",
    "#country_BALGARIJA\n",
    "#0= NO, 1= YES\n",
    "country_BALGARIJA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_BELGIQUE = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_CESKA_REPUBLIKA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_DANMARK = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_DEUTSCHLAND_OST = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_DEUTSCHLAND_WEST = np.array([0,1]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_EESTI = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ELLADA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ESPANA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_FRANCE = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_GREAT_BRITAIN = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_HRVATSKA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_IRELAND = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ITALIA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_KYPROS = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_LATVIA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_LIETUVA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_LUXEMBOURG = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_MAGYARORSZAG = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_MALTA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_NEDERLAND = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_POLSKA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_PORTUGAL = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ROMANIA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SLOVENIJA = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SLOVENSKA_REPUBLIC = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SUOMI = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_SVERIGE = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "country_ÖSTERREICH = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#type_community\n",
    "#0= NO, 1= YES\n",
    "type_community_Large_town = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "type_community_Rural_area_village = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "type_community_Small_middle_town = np.array([0,1]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#occupation\n",
    "#0= NO, 1= YES\n",
    "occupation_Employed = np.array([.50,.50]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "occupation_Not_active = np.array([.52,.48]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "occupation_Unemployed = np.array([.98,.02]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#GENDER\n",
    "#0= NO, 1= YES\n",
    "gender_Man = np.array([.51,.49]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "gender_Woman = np.array([.49,.51]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#marital_status\n",
    "#0= NO, 1= YES\n",
    "marital_status_Divorced_Separated = np.array([.94,.06]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Married = np.array([.53,.47]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Partnership = np.array([1,0]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Single = np.array([.60,.40]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "marital_status_Widow = np.array([.93,.07]).cumsum().searchsorted(np.random.sample(Total_Population))\n",
    "\n",
    "#generation of synthetic population\n",
    "features = [native, educational, age, household_composition, country_BALGARIJA, country_BELGIQUE, country_CESKA_REPUBLIKA, country_DANMARK, country_DEUTSCHLAND_OST, country_DEUTSCHLAND_WEST, country_EESTI, country_ELLADA, country_ESPANA, country_FRANCE, country_GREAT_BRITAIN, country_HRVATSKA, country_IRELAND, country_ITALIA, country_KYPROS, country_LATVIA, country_LIETUVA, country_LUXEMBOURG, country_MAGYARORSZAG, country_MALTA, country_NEDERLAND, country_POLSKA, country_PORTUGAL, country_ROMANIA, country_SLOVENIJA, country_SLOVENSKA_REPUBLIC, country_SUOMI, country_SVERIGE, country_ÖSTERREICH, marital_status_Divorced_Separated, marital_status_Married, marital_status_Partnership, marital_status_Single, marital_status_Widow, gender_Man, gender_Woman, occupation_Employed, occupation_Not_active, occupation_Unemployed, type_community_Large_town, type_community_Rural_area_village, type_community_Small_middle_town]\n",
    "df = pd.DataFrame(features)\n",
    "df = df.T\n",
    "population = df.as_matrix()\n",
    "\n",
    "#pickle.dump(population, open( \"models/DE72.pickle\", \"wb\" ) )\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "population_std = sc.transform(population)\n",
    "##TOTAL##\n",
    "prob_lr = lr.predict_proba(population_std)\n",
    "prob_lr = prob_lr[:, 0]\n",
    "prob_lr = np.average(prob_lr)\n",
    "prob_tree = tree.predict_proba(population)\n",
    "prob_tree = prob_tree[:, 0]\n",
    "prob_tree = np.average(prob_tree)\n",
    "prob_forest = forest.predict_proba(population)\n",
    "prob_forest = prob_forest[:, 0]\n",
    "prob_forest = np.average(prob_forest)\n",
    "prob_svm = svm.predict_proba(population_std)\n",
    "prob_svm = prob_svm[:, 0]\n",
    "prob_svm = np.average(prob_svm)\n",
    "prob_svm2 = svm2.predict_proba(population_std)\n",
    "prob_svm2 = prob_svm2[:, 0]\n",
    "prob_svm2 = np.average(prob_svm2)\n",
    "prob_knn = knn.predict_proba(population)\n",
    "prob_knn = prob_knn[:, 0]\n",
    "prob_knn = np.average(prob_knn)\n",
    "-\n",
    "print([Code_of_nuts2, prob_lr, prob_tree, prob_forest, prob_svm, prob_svm2, prob_knn, \n",
    "       prob_lr_models_nov_2015, prob_tree_models_nov_2015, prob_forest_models_nov_2015, prob_svm_models_nov_2015, \n",
    "       prob_svm2_models_nov_2015, prob_knn_models_nov_2015, prob_lr_models_may_2016, prob_tree_models_may_2016, \n",
    "       prob_forest_models_may_2016, prob_svm_models_may_2016, prob_svm2_models_may_2016, prob_knn_models_may_2016, \n",
    "       prob_lr_models_nov_2016, prob_tree_models_nov_2016, prob_forest_models_nov_2016, prob_svm_models_nov_2016, \n",
    "       prob_svm2_models_nov_2016, prob_knn_models_nov_2016, prob_lr_models_may_2017, prob_tree_models_may_2017, \n",
    "       prob_forest_models_may_2017, prob_svm_models_may_2017, prob_svm2_models_may_2017, prob_knn_models_may_2017, \n",
    "       prob_lr_models_nov_2017, prob_tree_models_nov_2017, prob_forest_models_nov_2017, prob_svm_models_nov_2017, \n",
    "       prob_svm2_models_nov_2017, prob_knn_models_nov_2017])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
